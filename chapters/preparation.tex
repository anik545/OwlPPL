% !TeX root = ../diss.tex

In this chapter, I will discuss the research done before starting the project, and some of the design decisions made based on this. In particular, common patterns in OCaml (and functional programming in general), influenced the final DSL, as well as the design of other similar probabilistic programming systems. I also give a general description on several classes of inference algorithms.

\section{Starting Point}

There do exist PPLs for OCaml, such as IBAL \cite{ibal} or HANSEI \cite{kiselyov2009embedded}, as well as PPLs for other languages, such as WebPPL - JavaScript\cite{mobus2018structure}, Church - LISP\cite{goodman2012church} or Infer.Net - F\#\cite{wang2011using} to name a few. My PPL can draw on some of the ideas introduced by these languages, particularly in implementing efficient inference engines. I will need to research the different approaches taken by these PPLs and decide what form of PPL to implement, especially in deciding the types of model I will want my PPL to be able to represent and the inference methods I implement.

I will be using an existing OCaml numerical computation library (Owl). This library does not contain methods for probabilistic programming in general, although it does contain modules which will help in the implementation of an inference engine such as efficient random number generation and lazy evaluation.

I have experience with the core SML language, which will aid in learning basic OCaml due to similarities in the languages, however I will still have to learn the modules system. 1B Foundations of Data Science also gives me a basic understanding of Bayesian inference. I did not have experience with domain specific languages in OCaml, although the 1B compilers course did implement a compiler and interpreter in OCaml.

\section{Requirements}

Before starting to write any code, I made sure to set out the features I aimed to implement for my DSL. The main goal was to produce a usable language, which was defined by the following criteria:

% TODO: which tense to use here - past, say "this met the success criteria as follows"
\begin{itemize}
	\item \textbf{Language Features}: Since I have written an embedded DSL, a user of my PPL should be able to take advantage of all standard OCaml features in the deterministic parts of their models. I need to make sure that this is the case, and features such as recursive or higher order functions will work.
	\item \textbf{Available distributions}: I aimed to make sure my PPL has at minimum the Bernoulli and normal distributions available as basic building blocks to build more complex probabilistic programs.
	\item \textbf{Correctness of inference}: I used the PPL developed on example problems to ensure correct results are produced. These results were compared to results produced in other PPLs as well as comparisons to analytic solutions for simple problems.
	\item \textbf{Available Inference Algorithms}: I aimed to include at least one available inference algorithm. However, since different problems are more or less well suited to different general-purpose inference procedures, I wrote implementations for five separate algorithms.
	\item \textbf{Performance}: This is a quantitative measure, comparing programs written in my PPL to equivalent programs in other PPLs. I used the profiling tools spacetime and GProf to profile my OCaml code. Performing inference should be possible within a reasonable amount of time, even though the project does not have a significant focus on performance.
	      % I also benchmarked the performance with regards to scalability, i.e. made sure the performance is still reasonable as models are conditioned on more data.
\end{itemize}

\section{Professional Practice}

I adopted several best practices in order to ensure the project was successful. This includes performing regular testing, splitting code into separate modules designing signatures first, and ensuring my code follows a consistent style (Jane Street)\footnote{\url{https://opensource.janestreet.com/standards/}}.

\subsection{Testing} \label{sec:prep-testing}

Testing systems which are linked to randomness can be quite tricky, as it is difficult to test behaviour that is expected to change from one execution to the next. One approach is to set a fixed random seed and make sure the same sequence of results are produced. The aim of a unit test, however, is to make sure that a desired property does not change from one version of the code to the next. Even with a fixed random seed, a change in code may cause new outputs even though the fundamental statistical property desired hasn't changed. Another approach is to perform some statistical test such as kolmogorov-smirnov \cite{massey1951kolmogorov}, to ensure distributions produced by my library are equal to what is expected. A problem with tests of this kind is that they are expected to fail sometimes, meaning unit tests will provide limited utility due to their inherent flakiness with random programs. In fact, since we expect these tests to fail a certain percentage of the time, if they do not sometimes fail there is a problem with our program.

As such, most of the unit tests I wrote are fairly simple and only catch very basic bugs. Unit tests were possible to write for the exact inference procedure when working with discrete distributions, since we always expect the same output distribution. However, all the other inference algorithms are approximate, so tests suffer from the problems described above. I was still able to carry out a full evaluation, performing hypothesis tests such as the kolmogorov-smirnov or chi-squared tests.

However, there are several auxiliary functions that can be tested effectively using conventional methods, so I was able to test them as normal. I also used the \texttt{Quickcheck} library to perform tests, which allows me to ensure certain invariants are preserved by functions by testing on large amounts of randomly generated inputs. I also use the \texttt{bisect\_ppx} library to produce code coverage reports so that I can ensure I am thoroughly testing code.

% talk about using very basic unit tests
% unit testing ppl is 
% include maths about hypothesis tests here - HAVE TO FAIL SOMETIMES otherwise the program is wrong
% include unit tests for exact inference
% go though how to solve this in implementations
% find some sources for how other people solve this, reference that here.

\subsection{Continuous Integration}
Since I will be developing a library, it is important to make sure that any unit tests are run regularly to ensure there are no regressions - no new code affects old behaviour. It is also important to make sure the library will function on different platforms, and that documentation is built (and possibly uploaded) automatically. To achieve this, I will be using GitHub's continuous integration service, `actions' to make sure code on the master branch always works. The CI can also be used to ensure the library works with older versions of OCaml, and is backwards-compatible.

\subsection{Licenses}

The libraries I use, Owl and Jane Street Core, are both licensed under the MIT license. This allows me to freely open-source my work using a similar license.
% what else do i write here - the pink book says to talk about licenses
% quickcheck is BSD
% alcotest is ISC
\section{Tools and Technologies}
The main tools I used are listed here:
\begin{itemize}
	\item Ocaml 4.08 - The language I wrote the main PPL library in
	\item Dune - Build system for OCaml
	\item Opam - OCaml package manager
	\item Alcotest - Unit testing framework
	\item Quickcheck - Random testing library
	\item Bisect\_ppx - Code coverage tool
	\item Spacetime - Memory profiler for OCaml
	\item Gprof - A Linux profiler
	      % \item Landmarks - Profiler for OCaml
	\item Owl - Scientific computing library in OCaml
	\item VSCode (with ocaml extensions) - IDE for OCaml development
	\item Git with GitHub - version control
\end{itemize}

Using OCaml 4.08 allows me to use new features of OCaml, in particular the ability to define custom let operators as syntax sugar for monads. The dune build system also allows me to more easily manage building and testing my code, as well as automatically creating documentation from comments and function signatures in my code. The profilers I used allowed me to work out the causes of performance issues and remedy them.

\section{OCaml}
I have chosen to use the OCaml language to implement my PPL. There are many features of OCaml which make it suitable for writing a DSL. Using OCaml, I can make sure that expressions in the DSL are well-typed, so that programs don't fail to run. OCaml's algebraic datatypes also make it easy to represent probabilistic programs as trees, and pattern matching makes it easy to 'interpret' and transform these trees. The module system also makes sure that certain types are hidden from the user, which can ensure only valid structures are created by the user.

\subsection{GADTs}
The main data structure I use to represent distributions is GADT - a generalised algebraic data type. GADTs are similar to ADTs (sum types), in that they have a set of constructors, but the main difference is that these constructors can have their output types annotated. The fact that the return types of constructors can vary is what makes GADTs more general than normal ADTs, whose return types are all the same. In OCaml, the syntax for this is \mintinline{ocaml}|type _ t = Constructor : a_type' -> a_type' t ...| . Since we can now know which constructors produce which concrete types of t (e.g. an \texttt{int t} or a \texttt{float t}, etc.), functions can be defined to only accept certain constructors, and we can make sure the whole structure is well typed.

Type inference for GADTs is undecidable, and so type inference often fails when pattern matching on GADTs, especially for recursive functions. I often need to annotate functions as being explicitly polymorphic using the syntax \mintinline{ocaml}|let f: 'a.'a t -> 'a t = fun x -> ...|.

\subsection{Monads}
% how in-depth should my explanation of a monad be?
Monads are a design pattern commonly used in functional programming languages.
	
The key data structure I use to model probability distributions is a monad. A data type is a monad if it defines two operations, \texttt{return} and \texttt{bind}, and can be thought of as datatypes which `wrap' values. The return function takes a value and returns a monad wrapping that value. The bind function takes a monad and a function, and applies the function to the value wrapped inside the monad, and rewraps this value. The type must also satisfy a set of laws, which I omit here\cite{wadler1990comprehending}. Monads can be used to structure programs in a general way, and allow side effects to be described in a pure way.
	
\subsubsection{Probability Monad}
It has been shown that probability distributions form a monad, \cite{giry1982categorical} \cite{jones1989probabilistic}, and that they can be used to create distributions composed from other distributions \cite{ramsey2002stochastic}. In this case, \texttt{return x} represents a distribution with only one value, x (technically a Dirac distribution). So \texttt{bind d f} is the main operator for composing distributions. Binding distributions together represents taking the output of one distribution (d) and using it in the body of the function (f). It can be thought of as taking a sample from d, however, it is important to note that calling bind does not directly produce a sample, but exposes that structure to an interpreter (here the inference engine) which can then decide what to do at that point.

\subsubsection{Custom let operators}
Ocaml 4.08 allows me to define definitions for custom let operators. This is used to provide syntactic sugar for working with monads, and is similar to do-notation in Haskell. The reference documentation \footnote{\url{http://caml.inria.fr/pub/distrib/ocaml-4.08/ocaml-4.08-refman.html}} outlines this, and a monad should provide a module which implements the (let*) and (and*) operators. The (let*) operator is the standard bind function - here it takes the identifier bound to as the first argument to the function in bind. The (and*) operator is the product operation, it takes two monads and returns the monad pair - it has signature \texttt{'a m -> 'b m -> ('a*'b) m}, where m is the monad type. An example, using the Option monad is given below to show the transformation that takes place. This syntax allows the user to not have to use the bind (or the alias \texttt{>>=}) explicitly, and offers a more intuitive syntax.

% \begin{noindent}
\begin{figure}[!htb]
	\centering														
	\begin{minipage}{0.45\textwidth}
		\centering
		\begin{ocamlcode-in}
open Option
(* new syntax *)
let add_options x y = 
  let* a = x in
  let* b = y in
  x+y
		\end{ocamlcode-in}
	\end{minipage}
	\begin{minipage}{0.45\textwidth}
		\centering
\begin{ocamlcode-in}
open Option
(* old syntax *)
let add_options x y = 
  x >>= (fun a -> 
      y >>= (fun b ->
          a+b))
\end{ocamlcode-in}
	\end{minipage}
	\captionof{listing}{New let syntax which makes monadic binds easier to express}
\end{figure}
% \end{noindent}

\subsection{Modules}
The module system is a key feature of the OCaml language. Every function in OCaml is in a module, by default the name of the file it resides in. Modules can also have signatures, which define what code is visible to a user, and constrain the module. This allows modules to hide types and implementations to provide a clean API. Modules are often used to wrap a particular type, for example a list or map. This means that to create or manipulate that type, the user must go through the modules API, ensuring only permitted operations are carried out. This is a feature I've used in designing distribution types. Modules can also be dynamically created from other modules, using functors, which are functions from modules to modules. This technique is used extensively in the Core library, and it allows modules to be customised and extended.
	
In OCaml, the module language (functors, modules, signatures, etc.) and the core language (functions, values, types, etc.) are considered separate, and values can't contain modules. First class modules provide a way around this constraint, and allows modules to be used in much the same way as ordinary values. This allows us to simplify the creation of modules from the users point of view, and means a library can define functions to create modules which can then be used by other functions.
	
\section{Owl}
	
Owl is a scientific computing library written for OCaml \cite{owl}. Importantly for my PPL, it contains functions for working with a wide variety of statistical functions. In particular, it contains functionality relating to many common distributions, e.g. normal, beta, binomial, etc. Since my language will allow the user to combine these basic distributions into larger models, I will need to use these functions to allow sampling from and the ability to perform inference on models. In particular, it is important to be able to find the probability density function (pdf) and cumulative density function (cdf) of these distributions as well as sample from them. Another important feature of owl is it's plotting functionality which enabled me to write functions which visualise output distributions directly from OCaml.

\section{Approaches to probabilistic programming}
Existing PPLs take several different forms, both as standalone and embedded languages. The main trade-off that is made in the design of PPLs is the number of models that can be expressed in the language compared to how efficient inference is. One approach is graph-based, where a \textit{factor graph} is generated from the program, over which efficient inference can take place. This approach can be seen in languages such as infer.NET or JAGS, and has the benefit of very fast inference, particularly since efficient computation graph frameworks can be leveraged - an example is Edward \cite{edward}, which uses TensorFlow as a backend. However, these languages usually cannot represent infinite models or unbounded recursion. Another approach, taken by the likes of WebPPL or Anglican, is trace-based. This approach considers execution traces, with a `trace' being one run of a program, with all the intermediate variables taking a particular value. Inference algorithms can reason about these traces in order to produce a posterior distribution, as will be seen in the next section. A trace-based approach often leads to clearer programs, since we are not working with a computation graph. It also leads to more models being able to be expressed , since we are not limited by the constraints of a graph. These languages are often referred to as being `universal'. However, inference is often slower, particularly when dealing with data in high dimensions, since inference algorithms need to be more general purpose, and often converge slower.
	
\section{Bayesian Inference}
Inference is the key motivating feature of probabilistic programming, and is a way to infer a distribution over the parameters based on the data we observe. The main feature of Bayesian inference is that we assign every model some prior belief. Often this prior is chosen based on our knowledge of the problem, but the prior can also be uninformative. The goal of Bayesian inference is to calculate the posterior distribution, which can be represented by Bayes' formula,
$$P(A\mid B)={\frac {P(B\mid A)P(A)}{P(B)}}$$
with $P(A)$ being the prior, and $P(B\mid A)$ being the likelihood model we define. In the PPL setting, the prior is the generative model we define, with condition statements defining the likelihood. Running inference on the program then produces a sampler for the posterior.

This formula holds for the continuous case too, using probability density functions ($f_X$),
% 
$$ f_{X\mid Y=y}(x)={\frac {f_{Y\mid X=x}(y)f_{X}(x)}{f_{Y}(y)}} $$
% 
% Unfortunately, exact Bayesian inference is usually computationally infeasible, especially when the number of random variables we consider is large. 

% For example, consider a set of discrete random variables ${X_i}$, with p the joint probability distribution of all $X_i$. The marginal distribution of any individual $X_i$ is:
% % 
% % How does this relate to the inference problem?
% $$P(X_i=x) = \sum_{j=0}^{50} p(X_1=x_i ... X_=y_i)$$

Unfortunately, exact Bayesian inference is usually computationally infeasible, especially when the number of random variables we consider is large. If we have 50 variables which can take one of two values, then we have to sum over $2^{50}$ values. There do exist some algorithms which operate on Bayesian networks (DAGs which represent random variables and their interdependence), and reduce the number of calculations needed. These include static methods such as \textit{Variable Elimination} or \textit{Message Passing} \cite{belief-prop}.
% 
Alternatively, in the continuous case the formula is
% 
$$P(\theta\mid x)=\frac{P(x\mid\theta)P(\theta)}{P(x)}$$
with 
$$P(x)=\int_{\Theta}P(x,\theta)~d\theta $$
% 
The normalizing constant here is an integral that often does not have an analytic solution, and so must be approximated. Another issue is that directly sampling from a distribution requires that we also invert this formula (in order to use inversion sampling).
% 
\section{Inference Algorithms}
% https://ermongroup.github.io/cs228-notes/inference/sampling/
% https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture17.pdf
	
% https://www.cs.ubc.ca/~fwood/teaching/OXWASP_CDT/probabilistic_programming.pdf
% http://www.robots.ox.ac.uk/~fwood/anglican/assets/pdf/Wood-AISTATS-2014.pdf
Inference algorithms are ways to systematically generate samples from posterior distributions given a likelihood function and a prior distribution. In probabilistic programming, a model consists of latent variables and observed variables, and a single execution of a model (a program) can be thought of as an assignment to each of these variables, known as an \textit{execution trace}. This can be defined mathematically as below, by Bayes' rule:
% 
$$p(x_{1:N}|y_{1:N})\propto \tilde{p}(y_{1:N},x_{1:N})$$ 
% 
Note that the trace may have a different number of variables each time a model is run, due to the fact that we allow general models which allow for unbounded recursion. 

Here, $p$ is the posterior distribution of a particular trace $x$, given the observed variables $y$. This is proportional to the joint distribution of all the variables ($\hat{p}$). The aim is then to find the posterior over the latent variables we are interested in (by marginalising the other variables). We can specify which variables we care about within the program, either as part of the model, or outside it in a query to the model.
	
In general, there are two classes of inference algorithms - static and dynamic\cite{gordon2014probabilistic}. In static methods, the program is compiled to a particular model (e.g. a Bayesian network), which is analysed for inference to be performed. These methods generally constrain the models that can be represented (often to finite graphical models). Since my PPL aims to be universal, I focus instead on dynamic methods, which use sampling to run programs and use conditioning statements that occur on these runs to perform inference.
	
\subsection{Exact Inference}
	
Exact Inference is the simplest method of calculating the posterior, but is usually computationally intractable. It involves calculating Bayes formula exactly, of which calculating the normalising constant is usually the problem. To sample directly, we would also need to find the inverse cumulative distribution to be able to use the inversion sampling method.
	
For discrete posterior distributions it can be thought of as calculating the probability of every possible value of the variable of interest. Since a random variable will be dependent on several others, this involves finding every possible combination of these variables and their outcomes.

\subsection{Rejection Sampling}
	
Since exact inference is too difficult in practice, we usually have to resort to \textit{Monte Carlo} \cite{monte-carlo} methods.
	
One such method, rejection sampling, is a very simple inference method which uses another distribution which \textit{can} be sampled from. We take samples from this proposal distribution, and either accept or reject them. How likely we are to accept or reject a sample depends on the pdf of this proposal distribution. It can be shown that samples taken using this method converge to the required distribution \cite{flury1990acceptance}. 
	
\subsection{Importance Sampling}
	
Importance sampling is another simple method, improving on rejection sampling, that can be used to sample from a target distribution using another distribution, known as the proposal distribution. We then calculate the ratio of the likelihoods between the two distributions to weight samples from the proposal. From doing this repeatedly with multiple samples from the proposal, we can build a posterior represented by a set of weighted samples.
	
% put proofs of inference methods here/implementation/appendix?
% Add equations
	
\subsection{Monte Carlo Markov Chains (MCMC)}
	
MCMC methods involve constructing a Markov chain with a stationary distribution equal to the posterior distribution. A Markov chain is a statistical model consisting of a sequence of events, where the probability of any event depends only on the previous event. The stationary distribution is the distribution over successive states that the chain converges to.
	
There exists several algorithms for finding this Markov chain, for example metropolis-hastings. This algorithm requires that we have a function, $f(x)$, which is proportional to the density of the distribution. The function is easy to compute for the posterior, since it is simply the prior multiplied by the posterior - the normalising constant can be ignored since we only need a proportional function.
	
MCMC algorithms have the same basic structure - to first `run' the chain for a burn-in period, taking samples and discarding them. Then, running the chain and collecting the states visited as samples. This set of samples is then a set of samples from the posterior, since the posterior should be equal to the stationary distribution. An important trade-off is made in the length of the burn-in period - too long and time is wasted discarding states, but too short and the chain will not converge to the correct distribution.
	
\subsection{Sequential Monte Carlo (SMC)}
	
SMC methods are algorithms which are based on using large numbers of weighted samples (`particles') to represent a posterior distribution. SMC methods are also known as particle filters. A particle is a value paired with an unnormalised weight which represents the likelihood of that value in the distribution. These particles are updated when data is observed and re-sampled from in order to converge the set of particles to the posterior.
	
For a set of weighted particles, 
$${\{(x^{[i]}, w^{[i]})\}}_{i=1..N}$$
the pdf of this distribution is represented by

\[
	p(x) = \sum_{i=1}^{N}w^{[i]}\delta_{x^{[i]}}(x)
\]
where $\delta$ is the Dirac distribution
	
The simplest SMC algorithms are particle filters\cite{particlefilter}, which simply resample particles on encountering new data, updating the weights of the particles based on how likely this data is deemed to be. However, many variations exist - the resampling method, updating the weights and the initialisation of particles can all be varied. The main feature of SMC algorithms is that they sequentially create sets of particles which converge to the desired distribution.

SMC methods can also be combined with MCMC methods to create new algorithms. These algorithms are known as particle Monte Carlo Markov chain (PMCMC) algorithms, and were first introduced for probabilistic programming in the Anglican language \cite{anglican-smc}.
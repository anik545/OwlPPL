% !TeX root = ../diss.tex
\chapter{Preparation}

\textit{This chapter describes the research carried out before starting the project and the professional practices followed throughout the project. I include an overview of the tools and technologies used, give a more detailed and mathematical account of probabilistic programming and describe of several classes of inference algorithms.}

\section{Starting Point}

There do exist PPLs embedded in OCaml, such as IBAL \cite{ibal} or HANSEI \cite{kiselyov2009embedded}. PPLs have also been embedded in other languages, such as WebPPL \cite{mobus2018structure}, Church \cite{goodman2012church} or Infer.Net \cite{wang2011using}. My PPL can draw on some of the ideas introduced by these languages, particularly in implementing efficient inference engines. I needed to research the different approaches taken by these PPLs and decide what form of PPL to implement, especially in deciding the types of model I will want my PPL to be able to represent and the inference methods I implement.

I used an existing OCaml numerical computation library (Owl). This library does not contain methods for probabilistic programming in general, but it does contain a large number of statistical functions for several distributions as well as efficient random number generation. Efficient computation of these functions is key to developing a performant PPL. 

I had experience with the core SML language, which aided in learning basic OCaml due to similarities in the languages, however I did have to learn the modules system. 1B Foundations of Data Science also gave me a basic understanding of Bayesian inference. I did not have experience with domain specific languages in OCaml, although the 1B compilers course did implement a compiler and interpreter in OCaml.

\section{Requirements}

Before starting to write any code, I made sure to set out the features I aimed to implement for my DSL. The main goal was to produce a usable language, which was defined by the following criteria:

% TODO: which tense to use here - past, say "this met the success criteria as follows"
\begin{itemize}
	\item \textbf{Language Features}: Since I have written an embedded DSL, a user of my PPL should be able to take advantage of all standard OCaml features in their models. I needed to make sure that this is the case, and features such as recursive or higher order functions will work.
	\item \textbf{Available distributions}: I aimed to make sure my PPL has at minimum the Bernoulli and normal distributions available as basic building blocks to build more complex probabilistic programs.
	\item \textbf{Correctness of inference}: I used the PPL developed on example problems to ensure correct results are produced. These results were compared to analytic solutions for simple problems.
	\item \textbf{Available Inference Algorithms}: I aimed to include at least one available inference algorithm. However, since different problems are more or less well suited to different general-purpose inference procedures, I wrote implementations for five separate algorithms.
	\item \textbf{Performance}: This is a quantitative measure, comparing programs written in my PPL to equivalent programs in other PPLs. I used the profiling tools spacetime and GProf to profile my OCaml code. Performing inference should be possible within a reasonable amount of time, even though the project does not have a significant focus on performance. I also benchmarked the performance with regards to scalability, i.e. made sure the performance is still reasonable as models are conditioned on more data.
\end{itemize}

\section{Tools and Technologies}
The main tools I used are listed here:
\begin{itemize}[itemsep=-1ex]
	\item Ocaml 4.08 - The host language for the PPL 
	\item Dune - Build system for OCaml
	\item Opam - OCaml package manager
	\item Alcotest - Unit testing framework
	\item Quickcheck - Invariant testing library with random input generation
	\item Bisect\_ppx - Code coverage tool
	\item Spacetime - OCaml-specific memory profiler for OCaml
	\item Gprof - Generic Linux profiler
	      % \item Landmarks - Profiler for OCaml
	\item Owl -  OCaml scientific computing library
	\item VSCode (with OCaml extensions) - IDE for OCaml development
	\item Git with GitHub - version control
\end{itemize}

Using OCaml 4.08 allows me to use new features of OCaml, in particular the ability to define custom let operators as syntax sugar for monads. I used the dune build system to more easily manage building and testing my code, as well as automatically creating documentation from comments and function signatures in my code. The profilers I used allowed me to work out the causes of performance issues and remedy them, as well as measure the performance to evaluate my PPL.

\subsection{OCaml}
I have chosen to use the OCaml language to implement my PPL. There are many features of OCaml which make it suitable for writing a DSL. Using OCaml, I can make sure that expressions in the DSL are well-typed, so that programs don't fail to run. OCaml's algebraic datatypes make it easy to represent probabilistic programs as trees, and pattern matching makes it easy to `interpret' and transform these trees. The module system also makes sure that certain types are hidden from the user, which ensures only valid values are created by the user.

\subsection{GADTs}
The main data structure I use to represent distributions is a generalised algebraic data type (GADT). GADTs are similar to ADTs (sum types), as they have a set of constructors, but these constructors can have their output types annotated with different return types. This makes GADTs more general than normal ADTs, whose return types are all the same. An example is a datatype to represent expressions:

% \begin{noindent}
\begin{listing}
\centering
\begin{cminted}{ocaml}
type _ expr = 
    F : float -> float t 
  | B : bool -> bool t 
  | Add: float t * float t -> float t
\end{cminted}
\end{listing}
% \end{noindent}
	
With this GADT, we can ensure that booleans can't be combined with \texttt{Add}, and statically check that expressions are well-typed and will not fail to evaluate, which would not be possible with an ordinary ADT.
	
Type inference for GADTs is undecidable, and so type inference often fails when pattern matching on GADTs, especially for recursive functions. I often need to annotate functions as being explicitly polymorphic using the syntax \mintinline{ocaml}|let f: 'a.'a t -> 'a t = fun x -> ...|.
	
\subsection{Monads}
Monads are a design pattern commonly used in functional programming languages.
	
The key data structure I use to model probability distributions is a monad. A data type is a monad if it defines two operations, \texttt{return} and \texttt{bind}, and can be thought of as datatypes which `wrap' values. The return function takes a value and returns a monad wrapping that value. The bind function takes a monad and a function, and applies the function to the value wrapped inside the monad, and rewraps this value. The type must also satisfy a set of laws, which I omit here\cite{wadler1990comprehending}. Monads can be used to structure programs in a general way, and allow side effects to be described in a pure way.
	
\paragraph{Probability Monad}
It has been shown that probability distributions form a monad, \cite{giry1982categorical, jones1989probabilistic}, and that they can be used to create distributions composed from other distributions \cite{ramsey2002stochastic}. In this case, \texttt{return x} represents a distribution with only one value (x) - technically a Dirac distribution, a distribution with only one value. So \texttt{bind d f} is the main operator for composing distributions. Binding distributions together represents taking the output of one distribution (d) and using it in the body of the function (f). It can be thought of as taking a sample from d, however, it is important to note that calling bind does not directly produce a sample, but exposes that structure to an interpreter (the inference engine) which can then decide what to do at each sample.
	
	
\paragraph{Custom let operators}
Ocaml 4.08 allows me to define definitions for custom let operators. This is used to provide syntactic sugar for working with monads, and is similar to do-notation in Haskell. The reference documentation \footnote{\url{http://caml.inria.fr/pub/distrib/ocaml-4.08/ocaml-4.08-refman.html}} outlines this, and a monad should provide a module which implements the (let*) and (and*) operators. The (let*) operator is the standard bind function - it takes the identifier bound to as the first argument to the function in bind. The (and*) operator is the product operation, it takes two monads and returns the monad pair - it has signature \texttt{'a m -> 'b m -> ('a * 'b) m}, where m is the monad type. An example, using the Option monad is given below to show the transformation that takes place. This syntax allows the user to not have to use the bind (or the alias \texttt{>>=}) explicitly, and offers a more intuitive syntax.
	
% TODO: add text within frame
% \begin{noindent}
\begin{figure}[!htb]
	\centering
	\begin{minipage}{0.45\textwidth}
		\centering
		\begin{ocamlcode-in}
			open Option
			(* new syntax *)
			let add_options x y = 
			  let* a = x in
			  let* b = y in
			  x+y
		\end{ocamlcode-in}
	\end{minipage}
	\begin{minipage}{0.45\textwidth}
		\centering
		\begin{ocamlcode-in}
			open Option
			(* old syntax *)
			let add_options x y = 
			  x >>= (fun a -> 
			    y >>= (fun b ->
			      a+b))
		\end{ocamlcode-in}
	\end{minipage}
	\captionof{listing}{New let syntax which makes monadic binds easier to express}
\end{figure}
% \end{noindent}
	
\subsection{Modules}
The module system is a key feature of the OCaml language. Every function in OCaml is in a module, by default the name of the file it resides in. Modules can also have signatures, which define what code is visible to a user, and constrain the module. Modules can hide types and implementations to provide a clean API, and are often used to wrap a particular type, for example a list or map. This means that to create or manipulate that type, the user must go through the modules API, ensuring only permitted operations are carried out. This is a feature I've used in designing distribution types. Modules can also be dynamically created from other modules, using functors, which are functions from modules to modules. This technique is used extensively in the Core library, and it allows modules to be customised and extended.
	
In OCaml, the module language (functors, modules, signatures, etc.) and the core language (functions, values, types, etc.) are considered separate, and values can't contain modules. First class modules provide a way around this constraint, and modules can be used in much the same way as ordinary values. This simplifies means a library can define functions to create modules which can then be used by other functions.
	
\subsection{Owl}
		
Owl is a scientific computing library written for OCaml \cite{owl}. It contains functions for working with a wide variety of probability distributions, e.g. normal, beta, binomial, etc. In particular, it is important to be able to find the probability density function (pdf) of distributions and to efficiently sample from distributions - these are the functions needed to perform inference. The distributions available in Owl form the primitive distributions I support, and are the building blocks of a probabilistic model.
	
Owl also provides many efficient helper functions, which can be used to calculate statistics over arrays of samples. Another important feature of owl is the plotting API for which I wrote a wrapper that can visualise output distributions from my PPL simply.
	
\section{Probabilistic Programming}
Probabilistic programming is a programming paradigm where statistical models can be described in terms of relations between random variables. Existing PPLs take two main forms - they can be standalone or embedded in another language. Standalone languages have their own syntax and compiler, so can be fine tuned to the task of inference, but often lack features since they have to be built from scratch. Embedded languages can utilise facilities in their host language, such as type checking, compilers or libraries, as well as allowing programs to be integrated into existing systems easily.
	
The other main trade-off that is made in the design of PPLs is the range of models that can be expressed in the language against the efficiency of inference. Many languages restrict the set of allowed models in order to use more efficient inference algorithms which can take advantage of the restricted structure of the allowed models. Universal languages can represent any model, but suffer from less predictable inference procedures since many properties of the model (such as the number of random variables) are not available at compile-time. Overall, the more general models that need to be supported, the less efficient inference is.
	
There are two main approaches to building PPLs. One approach is graph-based, where a \textit{factor graph} (a finite graph representing the variables and their relationships) is generated from a program, over which efficient inference can take place. This approach is used in languages such as infer.NET or JAGS, and has the benefit of being able to process high-dimensional data well, since efficient computation graph frameworks can be leveraged - an example is Edward \cite{edward}, which uses TensorFlow as a backend.
	
Another approach, taken by the PPLs such as Anglican or WebPPL, is trace-based. This approach considers execution traces, with a `trace' being one run of a program, where the intermediate random variables take a particular value. Inference algorithms reason about these traces in order to produce a posterior distribution. A trace-based approach can lead to more models being able to be expressed, since we are not limited by the constraints of a graph. However, inference is often slower, since inference algorithms need to be more general purpose, and often converge slower. I have taken a trace-based approach in OwlPPL in order to allow my language to represent models which uses regular OCaml language constructs.
		
\subsection{Bayesian Inference}
Inference is the key motivating feature of probabilistic programming, and is a way to find a distribution over some input parameters based on the data we observe. The main feature of Bayesian inference is that we assign every model some prior belief. Often this prior is chosen based on our knowledge of the problem, but the prior can also be uninformative. The goal of Bayesian inference is to calculate the posterior distribution, which can be represented by Bayes' formula,
% 
\[P(\theta\mid x)=\frac{P(x\mid\theta)P(\theta)}{P(x)}\propto{{P(x\mid\theta)P(\theta)}} \]
% 
with $P(\theta)$ being the prior, and $P(x\mid \theta)$ being the likelihood model we define - the probability of observing the data given some parameters $\theta$. Both $x$ and $\theta$ are often vectors of variables, representing multiple parameters and observations respectively.
	
Unfortunately, exact Bayesian inference is usually computationally infeasible, especially when the number of random variables  we consider is large. The main issue is computing the normalising factor $P(x)$,
\[P(x)=\int_{\Theta}P(x,\theta)~d\theta\]
This represents marginalising $x$ out of the joint distribution by summing over all possible values of $\theta$. If the state space becomes very large (or infinite), or if $\theta$ is a very large vector, computing this exactly is intractable. For some distributions, this integral does not even have a analytic solution.

% In addition, to sample from an arbitrary distribution, we need to use inverse transform sampling \cite{olver2013fast}:
% \begin{itemize}
% 	\item Given a distribution, $f(x)$, we need to find the cdf $F(x)$ and then invert it to get $F^{-1}(x)$.
% 	\item Generate a number $u$ from the distribution $U \tilde Uniform(0,1)$
% 	\item Compute $X = F^{-1}(u)$
% 	\item X is distributed according to 
% \end{itemize} 

This requires us to compute the cdf
% TODO: put inversion sampling here?
% 
In the PPL setting, the prior is the generative model we define. Conditioning statements define the likelihood model. Running the program forward without inference produces samples from the prior. Running inference on the program should then produces a new distribution, the posterior. Since the exact distribution can't be computed, inference algorithms I implement will return distributions which can only be sampled from. Other statistics can then be computed only by taking a large number of samples.
	
\subsection{Inference Algorithms}
% https://ermongroup.github.io/cs228-notes/inference/sampling/
% https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture17.pdf
			
% https://www.cs.ubc.ca/~fwood/teaching/OXWASP_CDT/probabilistic_programming.pdf
% http://www.robots.ox.ac.uk/~fwood/anglican/assets/pdf/Wood-AISTATS-2014.pdf

Inference algorithms are ways to systematically generate samples from posterior distributions given a likelihood function and a prior distribution. In probabilistic programming, a model consists of latent (internal) variables and observed variables, and a single execution of a model (a program) can be thought of as an assignment to each of these variables, known as an \textit{execution trace}. This can be defined mathematically as below, by Bayes' rule:
% 
\[p(x_{1:N}\mid y_{1:N})\propto \tilde{p}(y_{1:N},x_{1:N})\]\label{eq:trace}
% 
Note that the trace may have a different number of variables each time a model is run, due to the fact that we allow general models which allow for unbounded recursion. 

In \eqref{eq:trace}, $p$ is the posterior distribution of a particular trace $x$, given the observed variables $y$. This is proportional to the joint distribution of all the variables ($\hat{p}$). The aim is then to find the posterior over the latent variables we are interested in (by marginalising out the other variables). We can specify which variables we care about within the program, either as part of the model, or outside it in a query to the model.
% TODO: put in equation of marginalissation, explain marginalisation more.

In general, there are two classes of inference algorithms - static and dynamic \cite{gordon2014probabilistic} which correspond roughly to graph-based and trace-based methods respectively. In static methods, the program is compiled to a static structure (e.g. a Bayesian network), which is analysed for inference to be performed. These methods generally constrain the models that can be represented (often to finite graphical models). Since my PPL aims to be universal, I focused mainly on dynamic methods, which use sampling to run programs and use conditioning statements that occur on these runs to perform inference.

\subsubsection{Exact Inference}

Exact Inference is the simplest method of calculating the posterior, but is usually computationally intractable. It involves calculating Bayes formula exactly, of which calculating the normalising constant is usually the problem. For discrete posterior distributions it can be thought of as calculating the probability of every possible value of the variable of interest. Since a random variable will be dependent on several others, this involves enumerating every possible combination of these variables and their outcomes.

\subsubsection{Rejection Sampling}
			
Since exact inference is too difficult in practice, we usually have to resort to \textit{Monte Carlo} \cite{monte-carlo} methods.
		
One such method, rejection sampling, is a very simple inference method which uses another `proposal' distribution which \textit{can} be sampled from. We take samples from the proposal distribution, and either accept or reject them. How likely we are to accept or reject a sample depends on the pdf of this proposal distribution. It can be shown that samples taken using this method converge to the required distribution \cite{flury1990acceptance}. 
		
\subsubsection{Importance Sampling}
		
Importance sampling is another simple method, improving on rejection sampling, that can be used to sample from a target distribution using another distribution, known as the proposal distribution. We then calculate the ratio of the likelihoods between the two distributions to weight samples from the proposal. From doing this repeatedly with multiple samples from the proposal, we can build a posterior represented by a set of weighted samples.
			
% put proofs of inference methods here/implementation/appendix?
% Add equations
			
\subsubsection{Monte Carlo Markov Chains (MCMC)}
	
MCMC methods involve constructing a Markov chain with a stationary distribution equal to the posterior distribution. A Markov chain is a statistical model consisting of a sequence of events, where the probability of any event depends only on the previous event. The stationary distribution is the distribution over successive states that the chain converges to.
	
There exists several algorithms for finding this Markov chain, for example metropolis-hastings. This algorithm requires that we have a function, $f(x)$, which is proportional to the density of the distribution. The function is easy to compute for the posterior, since it is simply the prior multiplied by the posterior - the normalising constant can be ignored since we only need a proportional function.
	
MCMC algorithms have the same basic structure - to first `run' the chain for a burn-in period, taking samples and discarding them. Then, running the chain and collecting the states visited as samples. This set of samples is then a set of samples from the posterior, since the posterior should be equal to the stationary distribution. An important trade-off is made in the length of the burn-in period - too long and time is wasted discarding states, but too short and the chain will not converge to the correct distribution.

\subsubsection{Sequential Monte Carlo (SMC)}

SMC methods are algorithms which are based on using large numbers of weighted samples (`particles') to represent a posterior distribution. SMC methods are also known as particle filters. A particle is a value paired with an unnormalised weight which represents the likelihood of that value in the distribution. These particles are updated when data is observed and re-sampled from in order to converge the set of particles to the posterior.

For a set of weighted particles, 
\[{\{(x^{[i]}, w^{[i]})\}}_{i=1..N}\]
the pdf of this distribution is represented by

\[
	p(x) = \sum_{i=1}^{N}w^{[i]}\delta_{x^{[i]}}(x)
\]
where $\delta$ is the Dirac distribution.

The simplest SMC algorithms are particle filters \cite{particlefilter}, which simply resample particles on encountering new data, updating the weights of the particles based on how likely this data is deemed to be. However, many variations exist - the resampling method, updating the weights and the initialisation of particles can all be varied. The common feature of SMC algorithms is that they sequentially create sets of particles which converge to the desired distribution.

\subsubsection{Particle Monte Carlo Markov Chain (PMCMC)}
% TODO: pros/cons of all these?
SMC methods can also be combined with MCMC methods. These algorithms are known as particle Monte Carlo Markov chain (PMCMC) algorithms, and were first introduced for probabilistic programming in the Anglican language \cite{anglican-smc}. PMCMC methods are essentially MCMC algorithms which use an SMC algorithm as a proposal distribution.
		
		
\section{Professional Practice}
		
I adopted several best practices in order to ensure the project was successful. This includes performing regular testing, splitting code into separate modules designing signatures first, and ensuring my code follows a consistent style (Jane Street)\footnote{\url{https://opensource.janestreet.com/standards/}}.
		
\subsection{Testing} \label{sec:prep-testing}
% google "unit testing probabilistic functions"
% google "unit test mcmc sampler"
% https://discourse.mc-stan.org/t/advice-for-testing-probabilistic-code/9451
The statistical nature of my library makes it difficult to write thorough unit tests for inference and sampling procedures. Ensuring posterior samplers are correct is a difficult problem due to inherent randomness, and the solutions are covered in section \ref{sec:impl-testing}.

Despite this, there is a suite of unit tests for individual deterministic functions. This is especially important for deterministic helper functions which should always work the same way, and unit tests allow regressions to be caught. I also used the \texttt{Quickcheck} library to perform some unit tests, which allows me to ensure certain invariants are preserved by automatically testing on many randomly generated inputs. I use the \texttt{bisect\_ppx} library to produce code coverage reports so that I can ensure I am thoroughly testing code.

\subsection{Continuous Integration}
Since I will be developing a library, it is important to make sure that any unit tests are run regularly to ensure there are no regressions - no new code affects old behaviour. It is also important to make sure the library will function on different platforms, and that documentation is built (and possibly uploaded) automatically. To achieve this, I will be using GitHub's continuous integration service, `actions' to make sure code on the master branch always works. The CI can also be used to ensure the library works with older versions of OCaml, and is backwards-compatible.
		
\subsection{Licenses}
		
The libraries I use, Owl and Jane Street Core, are both licensed under the MIT license. This allows me to freely open-source my work using a similar license.
% what else do i write here - the pink book says to talk about licenses
% quickcheck is \BSD
% alcotest is \ISC
